{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.agents.agent_toolkits.pandas.base import create_pandas_dataframe_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI API key: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Kiểm tra xem biến môi trường 'GOOGLE_API_KEY' đã được thiết lập hay chưa\n",
    "if \"GOOGLE_API_KEY\" in os.environ:\n",
    "    api_key = os.environ[\"GOOGLE_API_KEY\"]\n",
    "    print(\"Google API Key đã được tải thành công:\")\n",
    "    # print(api_key)  # Hoặc chỉ kiểm tra bằng cách in ra một phần\n",
    "else:\n",
    "    print(\"Google API Key chưa được thiết lập trong biến môi trường.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "def load_llms_model(model_name: str):\n",
    "    \"\"\"\n",
    "    Load the Large Language Model for DataMate\n",
    "    \"\"\"\n",
    "    if \"gpt\" in model_name:\n",
    "        return ChatOpenAI(\n",
    "            model_name=model_name,\n",
    "            temperature=0.1,\n",
    "            max_tokens=1000,\n",
    "        )\n",
    "    elif \"gemini\" in model_name:\n",
    "        return ChatGoogleGenerativeAI(\n",
    "            model=model_name,\n",
    "            temperature=0.1,\n",
    "            # max_tokens=None,\n",
    "            # timeout=None,\n",
    "            # max_retries=2,\n",
    "            # other params...\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Model not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gemini-1.5-pro\"\n",
    "# MODEL_NAME = \"gpt-3.5-turbo\"\n",
    "\n",
    "llm = load_llms_model(MODEL_NAME)\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.invoke(\"Hello, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"D:\\HocTap\\HK2_Nam3\\Data_Mining\\score_Hoten.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_pandas_dataframe_agent(\n",
    "    df=df,\n",
    "    llm=llm,\n",
    "    agent_type=\"tool-calling\",\n",
    "    # agent_type = 'zero-shot-react-description',\n",
    "    allow_dangerous_code=True,\n",
    "    verbose=True,\n",
    "    return_intermediate_steps=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.ainvoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the average score of the students?\"\n",
    "response = agent(question)\n",
    "# response = agent.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response['intermediate_steps'][0][0].tool_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Plot every student's score\"\n",
    "response = agent(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response['intermediate_steps'][0][0].tool_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response['intermediate_steps'][0][0].tool_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
